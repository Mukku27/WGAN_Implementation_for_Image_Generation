{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "nhHbo0XFlg1y",
        "outputId": "e47da81b-7f50-4d63-8eb7-67774c507aa0"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'model_wgan'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-a44fec408ae2>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorboard\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodel_wgan\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDiscriminator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mGenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minitialize_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgradient_penalty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'model_wgan'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision as torchvision\n",
        "from torchvision import datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from model_wgan import Discriminator,Generator,initialize_weights\n",
        "from utils import gradient_penalty\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define device (CPU or GPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "LEARNING_RATE=1e-4\n",
        "Batch_size=64\n",
        "image_size=64\n",
        "channels_img=1\n",
        "z_dim=100\n",
        "num_epochs=10\n",
        "features_disc=64\n",
        "features_gen=64\n",
        "critc_iterations=5\n",
        "lambda_gp=10\n",
        "transforms=transforms.Compose(\n",
        "    [\n",
        "        transforms.Resize(image_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(\n",
        "            [0.5 for _ in range(channels_img)],[0.5 for _ in range(channels_img)]\n",
        "        ),\n",
        "\n",
        "    ]\n",
        "\n",
        ")\n",
        "\n",
        "dataset=datasets.ImageFolder(root='celeb_dataset',transform=transforms)\n",
        "loader=DataLoader(dataset,batch_size=Batch_size,shuffle=True)\n",
        "gen=Generator(z_dim,channels_img,features_gen).to(device)\n",
        "critic=Discriminator(channels_img,features_disc).to(device)\n",
        "initialize_weights(gen)\n",
        "initialize_weights(critic)\n",
        "opt_gen=optim.Adam(gen.parameters(),lr=LEARNING_RATE,betas=(0.5,0.999))\n",
        "opt_critic=optim.Adam(critic.parameters(),lr=LEARNING_RATE,betas=(0.5,0.999))\n",
        "\n",
        "fixed_noise=torch.randn(32,z_dim,1,1).to(device)\n",
        "writer_real=SummaryWriter(f\"logs/real\")\n",
        "writer_fake=SummaryWriter(f\"logs/fake\")\n",
        "step=0\n",
        "gen.train()\n",
        "critic.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "BH59ZR2cgo8b",
        "outputId": "75820037-544a-4082-a103-ee9ca5a4f4e1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'Compose' object has no attribute 'Compose'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-f1e40e8dc7ae>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mcritc_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mlambda_gp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m transforms=transforms.Compose(\n\u001b[0m\u001b[1;32m     14\u001b[0m     [\n\u001b[1;32m     15\u001b[0m         \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Compose' object has no attribute 'Compose'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "  for batch_idx,(real,_) in enumerate(loader):\n",
        "    real=real.to(device)\n",
        "\n",
        "    for _ in range(critic_iterations):\n",
        "        noise=torch.randn(Batch_size,z_dim,1,1).to(device)\n",
        "        fake=gen(noise)\n",
        "        critic_real=critic(real).reshape(-1)\n",
        "        critic_fake=critic(fake).reshape(-1)\n",
        "        gp=gradient_penalty(critic,real,fake,device=device)\n",
        "        loss_critic=(-(torch.mean(critic_real)-torch.mean(critic_fake))+lambda_gp*gp)\n",
        "        critic.zero_grad()\n",
        "        loss_critic.backward(retain_graph=True)\n",
        "        opt_critic.step()\n",
        "\n",
        "\n",
        "\n",
        "    output=critic(fake).reshape(-1)\n",
        "    loss_gen=-torch.mean(output)\n",
        "    gen.zero_grad()\n",
        "    loss_gen.backward()\n",
        "    opt_gen.step()\n",
        "\n",
        "\n",
        "    if batch_idx==0:\n",
        "       print(f\"Epochs[{epoch}\\ {num_epochs}]/\"\n",
        "             f\"Loss D:{loss_critic :.4f},Loss G:{lossG:.4f}\")\n",
        "       with torch.no_grad():\n",
        "         fake=gen(fixed_noise)\n",
        "\n",
        "         img_grid_fake=torchvision.utils.make_grid(fake[:32],normalize=True)\n",
        "         img_grid_real=torchvision.utils.make_grid(real[:32],normalize=True)\n",
        "\n",
        "\n",
        "         writer_fake.add_image(\n",
        "            \"MNIST fake images\",img_grid_fake,global_step=step\n",
        "        )\n",
        "         writer_real.add_image(\n",
        "            \"MNIST real images\",img_grid_real,global_step=step\n",
        "        )\n",
        "         step+=1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "hV9kyVmZgs6c",
        "outputId": "da8dcfe3-5c50-462c-ab69-b92ceabfc6cb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'loader' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-14c8ec3f545d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mreal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcritic_iterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'loader' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7Dw3_7SRilUe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}